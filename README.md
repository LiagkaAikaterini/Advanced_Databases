# Advanced Databases
This is a project developed for the ECE NTUA course "Advanced Topics in Databases" during the year of 2021-2022. 

## Project Overview
This project leverages Apache Spark to perform analytical queries on a subset of the Full MovieLens Dataset. The dataset consists of movie information, genres, and user ratings. The analysis covers data transformation and the execution of various queries using both RDD API and Spark SQL.

## Our Team
- [Aikaterini Liagka](https://github.com/LiagkaAikaterini)
- [Stela Zhara](https://github.com/stelazr)
- Alexopoulos Ioannis

## Datasets
The dataset we used for the analysis is a subset of the [Full MovieLens Dataset](https://grouplens.org/datasets/movielens/latest/). The version we leveraged can be found on [Kaggle](https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset). The exact Dataset we used can be downloaded [here](https://drive.google.com/file/d/1xoSWuhR7WB_BqU_l0rCLLDrHtgYbAJRE/view?usp=sharing) and it includes the following CSV files:

- **movies.csv (17 MB) :** Movie details. The key fields in this dataset are:
    - **_id_**: The unique identifier for each movie (integer).
    - **_title_**: The title of the movie (string). Titles may contain commas, so care must be taken when parsing this field.
    - **_description_**: A textual summary or synopsis of the movie (string).
    - **_release_date_**: The date the movie was released (timestamp in ISO format).
    - **_duration_**: The length of the movie in minutes (float).
    - **_budget_**: The production budget of the movie in US dollars (float). If unknown, the field may be empty or zero.
    - **_revenue_**: The total revenue generated by the movie in US dollars (float). If unknown, the field may be empty or zero.
    - **_popularity_**: A numeric representation of the popularity of the movie (float).

- **movie_genres.csv (1.3 MB) :** This dataset represents the genres that each movie belongs to. A single movie can belong to multiple genres, meaning there are multiple rows for movies with more than one genre. The fields in this dataset are:
  - **_movie_id_**: The unique identifier of the movie (integer). This corresponds to the id field in the `movies.csv` file.
  - **_genre_**: The genre or category of the movie (string). Genres can include values such as Action, Comedy, Drama, Fantasy, etc.
    
- **ratings.csv (677 MB) :** This dataset stores the ratings that users have given to the movies. Each row represents a single rating provided by a user for a specific movie at a certain time. The key fields are:
    - **_user_id_**: The unique identifier for the user who provided the rating (integer).
    - **_movie_id_**: The unique identifier of the movie that was rated (integer). This corresponds to the id field in the `movies.csv` file.
    - **_rating_**: The rating score provided by the user, typically on a scale from 0.5 to 5.0, in increments of 0.5 (float).
    - **_timestamp_**: The time at which the rating was submitted (integer, UNIX epoch format).

## Requirements
- Apache Spark (2.4.4 or newer)
- HDFS for file storage
- Python 3.x

## Objectives
### Part 1: Analytical Queries Using Apache Spark
The project implements five key queries using both RDD API and Spark SQL to gain insights from the data.

#### Queries:
**1.** Highest-grossing Movie per Year (From 2000 onward, ignoring entries with missing data)

**2.** Percentage of Users with Average Rating > 3

**3.** Average Rating and Count of Movies per Genre

**4.** Average Length of Movie Summaries (in words) for 'Drama' Movies per 5-year Period (from 2000)

**5.** Top User per Genre with Favorite and Least Favorite Movies Based on Ratings

### Part 2: Join Operations in Spark
Implementation and comparison of different join algorithms:

- Broadcast Join (Map-Side Join)
- Repartition Join (Reduce-Side Join)

## Installation
**1.** Clone the repository:

``` bash
git clone https://github.com/LiagkaAikaterini/Advanced_Databases.git
cd Advanced_Databases
```
**2.** Install Apache Spark: Follow the [official Spark installation guide](https://spark.apache.org/docs/latest/).

**3.** Ensure HDFS is running and load the dataset into HDFS:
```bash
hdfs dfs -put movie_data /path/to/hdfs/files
```

**4.** Run the Spark jobs using:
```bash
spark-submit script.py
```
**Note :** For the Spark SQL implementation of Query 1 (q1) the user must give the input format (csv || parquet). For example:
```bash
spark-submit q1_sql.py csv
```

## Results
The results of each query (both RDD and SQL) are located in th [output](output) folder. The Performance Comparison, which includes execution times visualized in bar charts and general analysis of our project can be located in our [report](report.pdf).

## Conclusions
This project demonstrates the efficiency and scalability of Apache Spark for large-scale data processing, utilizing both RDD and SQL APIs. It also provides insights into advanced database techniques, including data partitioning, indexing, and join optimization.
