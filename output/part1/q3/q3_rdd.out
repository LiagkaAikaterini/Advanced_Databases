-------------------------------------------------
Query 3 (RDD) Outputs
OUTPUT FORMAT: (genre, (vote_avg, movie_count))


('Action', (3.158532929451071, 1175))
('Adventure', (3.168709062525581, 707))
('Animation', (3.175885456020015, 223))
('Comedy', (3.137049467739954, 2113))
('Crime', (3.1625839378882317, 907))
('Documentary', (3.0742356093239853, 503))
('Drama', (3.1391216242914504, 3724))
('Family', (3.1569054919202837, 386))
('Fantasy', (3.142913521900702, 463))
('Foreign', (3.1139858344079134, 271))
('History', (3.118791045849541, 306))
('Horror', (3.1340202623924758, 723))
('Music', (3.189047782134767, 248))
('Mystery', (3.148769392655548, 475))
('Romance', (3.1562777018393633, 1206))
('Science Fiction', (3.157163683913988, 593))
('TV Movie', (3.148118069220998, 87))
('Thriller', (3.148281748166091, 1427))
('War', (3.114663382606141, 231))
('Western', (3.2140607181871017, 185))


Total execution time for Query 3 (Map Reduce Query) is: 54.51064682006836 sec

-------------------------------------------------
-------------------------------------------------
Query 3 (RDD) Outputs
OUTPUT FORMAT: (genre, (vote_avg, movie_count))


('Action', (3.1585329294510713, 1175))
('Adventure', (3.1687090625255814, 707))
('Animation', (3.1758854560200147, 223))
('Comedy', (3.1370494677399527, 2113))
('Crime', (3.1625839378882312, 907))
('Documentary', (3.0742356093239853, 503))
('Drama', (3.1391216242914504, 3724))
('Family', (3.1569054919202837, 386))
('Fantasy', (3.142913521900702, 463))
('Foreign', (3.1139858344079134, 271))
('History', (3.118791045849541, 306))
('Horror', (3.1340202623924758, 723))
('Music', (3.1890477821347663, 248))
('Mystery', (3.148769392655548, 475))
('Romance', (3.1562777018393633, 1206))
('Science Fiction', (3.1571636839139883, 593))
('TV Movie', (3.148118069220997, 87))
('Thriller', (3.148281748166091, 1427))
('War', (3.114663382606141, 231))
('Western', (3.2140607181871013, 185))


Traceback (most recent call last):
  File "/home/user/q3/q3_rdd.py", line 51, in <module>
    res_2 = res.map(list_to_csv_str).coalesce(1).saveAsTextFile("hdfs://master:9000/outputs/q3_rdd.csv")
  File "/home/user/spark-2.4.4-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/rdd.py", line 1570, in saveAsTextFile
  File "/home/user/spark-2.4.4-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1257, in __call__
  File "/home/user/spark-2.4.4-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/sql/utils.py", line 63, in deco
  File "/home/user/spark-2.4.4-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py", line 328, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o158.saveAsTextFile.
: org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://master:9000/outputs/q3_rdd.csv already exists
	at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)
	at org.apache.spark.internal.io.HadoopMapRedWriteConfigUtil.assertConf(SparkHadoopWriter.scala:289)
	at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:71)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1096)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1094)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1067)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1032)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply$mcV$sp(PairRDDFunctions.scala:958)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:957)
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply$mcV$sp(RDD.scala:1499)
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1478)
	at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1478)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1478)
	at org.apache.spark.api.java.JavaRDDLike$class.saveAsTextFile(JavaRDDLike.scala:550)
	at org.apache.spark.api.java.AbstractJavaRDDLike.saveAsTextFile(JavaRDDLike.scala:45)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)

